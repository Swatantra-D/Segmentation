{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transfer learning for the multimodal learning and segmentation\n",
        "#### This notebook trains autoencoder on stereozoom data and then transfers the weights to the U-net for multimodal learning and segmentation of OCT images which will be used to calculate the healing score\n",
        "\n",
        "## workflow:\n",
        "- 1. [install packages](#install-packages)\n",
        "- 2. [Libraries imports](#libraries-imports)\n",
        "- 3. [Data imports for autoencoder](#data-imports-for-autoencoder)\n",
        "- 4. [Train autoencoder](#train-autoencoder)\n",
        "- 5. [Transfer weights to unet and training](#transfer-weights-to-unet-and-training)\n",
        "- 6. [Plotting the predictions](#plotting-the-predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### install packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip install patchify\n",
        "! pip install segmentation_models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Libraries imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnIr7jrMfi7S"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "import segmentation_models as sm\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import load_model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import class_weight\n",
        "from patchify import patchify, unpatchify\n",
        "from keras.models import Model\n",
        "from tqdm import tqdm \n",
        "from keras.metrics import MeanIoU\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.utils import class_weight\n",
        "from patchify import patchify, unpatchify\n",
        "from tensorflow.keras.utils import normalize\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import normalize, img_to_array, to_categorical\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data imports for autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzdA-JzZf8TX",
        "outputId": "56d31a6b-3da1-43bf-bf48-dc61b50d41e7"
      },
      "outputs": [],
      "source": [
        "# specify parameters and load stereozoom data\n",
        "SIZE=256\n",
        "n_classes = 4\n",
        "img_data=[]\n",
        "path1 = '/content/drive/MyDrive/Image_dataset/image'\n",
        "files=os.listdir(path1)\n",
        "for i in tqdm(files):\n",
        "    img=cv2.imread(path1+'/'+i,1)   #Change 0 to 1 for color images\n",
        "    img=cv2.resize(img,(SIZE, SIZE))\n",
        "    img_data.append(img_to_array(img))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMfp_kbBgOBe"
      },
      "outputs": [],
      "source": [
        "# reshape data into a numpy array\n",
        "img_array = np.reshape(img_data, (len(img_data), SIZE, SIZE, 3))\n",
        "img_array = img_array.astype('float32') / 255.\n",
        "img_array2 = img_array[:576]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4yx1PMogbpy"
      },
      "outputs": [],
      "source": [
        "# define double convolution blocks\n",
        "def conv_block(input, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
        "    x = BatchNormalization()(x)   #Not in the original network. \n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)  #Not in the original network\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "# define encoder blocks\n",
        "def encoder_block(input, num_filters):\n",
        "    x = conv_block(input, num_filters)\n",
        "    p = MaxPool2D((2, 2))(x)\n",
        "    return x, p   \n",
        "\n",
        "# define decoder blocks\n",
        "def decoder_block(input, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "# assemble encoder part of the network\n",
        "def build_encoder(input_image):\n",
        "    #inputs = Input(input_shape)\n",
        "\n",
        "    s1, p1 = encoder_block(input_image, 64)\n",
        "    s2, p2 = encoder_block(p1, 128)\n",
        "    s3, p3 = encoder_block(p2, 256)\n",
        "    s4, p4 = encoder_block(p3, 512)\n",
        "    \n",
        "    encoded = conv_block(p4, 1024) #Bridge\n",
        "    \n",
        "    return encoded\n",
        "\n",
        "# assemble decoder part of the network\n",
        "def build_decoder(encoded):\n",
        "    d1 = decoder_block(encoded, 512)\n",
        "    d2 = decoder_block(d1, 256)\n",
        "    d3 = decoder_block(d2, 128)\n",
        "    d4 = decoder_block(d3, 64)\n",
        "    \n",
        "    decoded = Conv2D(3, 3, padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "    return decoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTKYHa1jiDAj"
      },
      "outputs": [],
      "source": [
        "# assemble the autoencoder network\n",
        "def build_autoencoder(input_shape):\n",
        "    input_img = Input(shape=input_shape)\n",
        "    autoencoder = Model(input_img, build_decoder(build_encoder(input_img)))\n",
        "    return(autoencoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nR8DN4YTiIgD"
      },
      "outputs": [],
      "source": [
        "# deine decoder blocks for U-Net\n",
        "def decoder_block_for_unet(input, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6I1XeePziMp3"
      },
      "outputs": [],
      "source": [
        "# build the U-Net network with same dimentions as the autoencoder\n",
        "def build_unet(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    s1, p1 = encoder_block(inputs, 64)\n",
        "    s2, p2 = encoder_block(p1, 128)\n",
        "    s3, p3 = encoder_block(p2, 256)\n",
        "    s4, p4 = encoder_block(p3, 512)\n",
        "\n",
        "    b1 = conv_block(p4, 1024) #Bridge\n",
        "\n",
        "    d1 = decoder_block_for_unet(b1, s4, 512)\n",
        "    d2 = decoder_block_for_unet(d1, s3, 256)\n",
        "    d3 = decoder_block_for_unet(d2, s2, 128)\n",
        "    d4 = decoder_block_for_unet(d3, s1, 64)\n",
        "\n",
        "    \n",
        "    outputs = Conv2D(n_classes, (1, 1), activation='softmax')(d4)  #Binary (can be multiclass)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"U-Net\")\n",
        "    print(model.summary())\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBHFi8NTiSD5",
        "outputId": "59ef5ae8-3eef-4c0b-d9c9-f090e0647366"
      },
      "outputs": [],
      "source": [
        "# compile the autoencoder model\n",
        "autoencoder_model=build_autoencoder(img.shape)\n",
        "autoencoder_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
        "print(autoencoder_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abNWnkxKiamd",
        "outputId": "fb291529-c991-4622-92a1-e476b5757305"
      },
      "outputs": [],
      "source": [
        "# train to get weights for the U-Net\n",
        "history = autoencoder_model.fit(img_array2, img_array2,\n",
        "        epochs=100, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ACW26W2igUo"
      },
      "outputs": [],
      "source": [
        "# save the weights\n",
        "autoencoder_model.save('autoencoder_multimodal_100epochs.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "M5Z62Jo8i_Hf",
        "outputId": "f231ab12-61f6-4c54-ce7b-a624de9a67c4"
      },
      "outputs": [],
      "source": [
        "# load the weights\n",
        "autoencoder_model = load_model(\"autoencoder_multimodal_100epochs.h5\", compile=False)\n",
        "       \n",
        "# check the reconstructed images\n",
        "num=random.randint(0, len(img_array2)-1)\n",
        "test_img = np.expand_dims(img_array[num], axis=0)\n",
        "pred = autoencoder_model.predict(test_img)\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(test_img[0])\n",
        "plt.title('Original')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(pred[0].reshape(SIZE,SIZE,3))\n",
        "plt.title('Reconstructed')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### transfer weights to unet and training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS7QgqJvjKxS",
        "outputId": "116553fe-3ade-458b-980b-66285affbf78"
      },
      "outputs": [],
      "source": [
        "#Now define encoder model only, without the decoder part. \n",
        "input_shape = (256, 256, 3)\n",
        "input_img = Input(shape=input_shape)\n",
        "\n",
        "encoder = build_encoder(input_img)\n",
        "encoder_model = Model(input_img, encoder)\n",
        "print(encoder_model.summary())\n",
        "\n",
        "num_encoder_layers = len(encoder_model.layers) #35 layers in our encoder. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84Thl8t8zbGS",
        "outputId": "aa73dc1c-a94d-4b00-e1fd-be4239833591"
      },
      "outputs": [],
      "source": [
        "#Get weights for the 35 layers from trained autoencoder model and assign to our new encoder model \n",
        "for l1, l2 in zip(encoder_model.layers[:35], autoencoder_model.layers[0:35]):\n",
        "    l1.set_weights(l2.get_weights())\n",
        "\n",
        "#Verify if the weights are the same between autoencoder and encoder only models. \n",
        "autoencoder_weights = autoencoder_model.get_weights()[0][1]\n",
        "encoder_weights = encoder_model.get_weights()[0][1]\n",
        "\n",
        "#Save encoder weights for future comparison\n",
        "np.save('pretrained_encoder-weights.npy', encoder_weights )\n",
        "\n",
        "\n",
        "#Check the output of encoder_model on a test image\n",
        "#Should be of size 16x16x1024 for our model\n",
        "temp_img = cv2.imread('/content/drive/MyDrive/Image_dataset/image/106.png',1)\n",
        "temp_img = cv2.resize(temp_img,(256,256))\n",
        "temp_img = temp_img.astype('float32') / 255.\n",
        "temp_img = np.expand_dims(temp_img, axis=0)\n",
        "temp_img_encoded=encoder_model.predict(temp_img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70vnaVOdzgMh",
        "outputId": "aaed0785-de4a-4b7d-d04c-61cf6ecc1769"
      },
      "outputs": [],
      "source": [
        "#Now let us define a Unet with same encoder part as out autoencoder. \n",
        "#Then load weights from the original autoencoder for the first 35 layers (encoder)\n",
        "input_shape = (256, 256, 3)\n",
        "unet_model = build_unet(input_shape)\n",
        "\n",
        "#Print layer names for each model to verify the layers....\n",
        "#First 35 layers should be the same in both models. \n",
        "unet_layer_names=[]\n",
        "for layer in unet_model.layers:\n",
        "    unet_layer_names.append(layer.name)\n",
        "\n",
        "autoencoder_layer_names = []\n",
        "for layer in autoencoder_model.layers:\n",
        "    autoencoder_layer_names.append(layer.name)\n",
        "    \n",
        "#Make sure the first 35 layers are the same. Remember that the exct names of the layers will be different.\n",
        "\n",
        "#Set weights to encoder part of the U-net (first 35 layers)\n",
        "for l1, l2 in zip(unet_model.layers[:35], autoencoder_model.layers[0:35]):\n",
        "    l1.set_weights(l2.get_weights())\n",
        "\n",
        "unet_model.compile('Adam', loss=sm.losses.categorical_focal_jaccard_loss, metrics=[sm.metrics.iou_score])\n",
        "#unet_model.compile(optimizer=Adam(lr = 1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "unet_model.summary()\n",
        "print(unet_model.output_shape)\n",
        "\n",
        "unet_model.save('unet_model_weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxyWy7MOM1Ch"
      },
      "outputs": [],
      "source": [
        "# specify parameters for OCT images\n",
        "SIZE_X = 512\n",
        "SIZE_Y = 128*13 #1712\n",
        "\n",
        "patch_size = (256, 256,3)\n",
        "window_step = 128 # 128\n",
        "n_classes=4 \n",
        "\n",
        "batch_size = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMyC1XYGM4VB"
      },
      "outputs": [],
      "source": [
        "# load OCT images\n",
        "train_images = []\n",
        "\n",
        "for img_path in sorted(glob.glob(os.path.join(\"/content/drive/MyDrive/OCT_DATASET/Images\", \"*.BMP\"))):\n",
        "    img = cv2.imread(img_path, 1)\n",
        "    p_imgs = patchify(img, patch_size, step=window_step).reshape(-1,*patch_size) # split image into patches\n",
        "    # print(img.shape)      \n",
        "    # img = cv2.resize(img, (SIZE_Y, SIZE_X))\n",
        "    train_images.append(p_imgs)\n",
        "train_images = np.concatenate(train_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lS0YIFEGNBt4",
        "outputId": "8ddc292f-6e30-445a-8b8a-20c23ad5a8d4"
      },
      "outputs": [],
      "source": [
        "train_images.shape # check the shape of the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQJTZxu2NFCv"
      },
      "outputs": [],
      "source": [
        "patch_size=(256,256) # size of the patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvVAjcJ5NIQH"
      },
      "outputs": [],
      "source": [
        "# load OCT masks\n",
        "train_masks = [] \n",
        "for mask_path in sorted(glob.glob(os.path.join(\"/content/drive/MyDrive/OCT_DATASET/Mask\", \"*.png\"))):\n",
        "    mask = cv2.imread(mask_path,cv2.IMREAD_UNCHANGED)\n",
        "    p_imgs = patchify(mask, patch_size, step=window_step).reshape(-1,*patch_size)  # split into patches \n",
        "    #mask = cv2.resize(mask, (SIZE_Y, SIZE_X)) \n",
        "    train_masks.append(p_imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P39PaicaWgkt"
      },
      "outputs": [],
      "source": [
        "train_masks = np.expand_dims((np.array(train_masks)), 3) /255. # normalize masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d75l86hCO2kj",
        "outputId": "fb624302-e871-4cee-98ac-ad410a09cf27"
      },
      "outputs": [],
      "source": [
        "train_masks.shape # check the shape of the masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sXU3925O8Rs",
        "outputId": "dabc64b7-5577-4b7c-8c0c-d85d83bedafd"
      },
      "outputs": [],
      "source": [
        "# remove the patches with only one class (this will remove the patches with only background, because the other patches will almost always have atleast 2 classes)\n",
        "idx_lst = []\n",
        "for i, single_mask in enumerate(train_masks):\n",
        "  if len(np.unique(single_mask)) > 1:\n",
        "    idx_lst.append(i)\n",
        "len(idx_lst), train_images.shape, train_images[idx_lst].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XzYzql5PHot"
      },
      "outputs": [],
      "source": [
        "# take the patches with more than one class\n",
        "train_images, train_masks = train_images[idx_lst], train_masks[idx_lst]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-24dEYurPWoK"
      },
      "outputs": [],
      "source": [
        "# test split\n",
        "X1, X_test, y1, y_test = train_test_split(train_images,train_masks, test_size = 0.10, random_state = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15QRHavBPZQl"
      },
      "outputs": [],
      "source": [
        "# train validation split\n",
        "X_train, X_do_not_use, y_train, y_do_not_use = train_test_split(X1, y1, test_size = 0.2, random_state = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biheX49qPcrO",
        "outputId": "9c22bfa6-0ffc-4d44-98f5-9c91304ca1b2"
      },
      "outputs": [],
      "source": [
        "# check shapes\n",
        "X_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "FjijtoqhPfqp",
        "outputId": "ac28e956-e8a1-4f91-e048-e7ad8e1fa6f0"
      },
      "outputs": [],
      "source": [
        "# convert training masks to categorical\n",
        "train_masks_cat = to_categorical(y_train, num_classes=n_classes)\n",
        "y_train_cat = train_masks_cat.reshape((y_train.shape[0], y_train.shape[1], y_train.shape[2], n_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdZggKJWPjOc"
      },
      "outputs": [],
      "source": [
        "# convert testing masks to categorical\n",
        "test_masks_cat = to_categorical(y_test, num_classes=n_classes)\n",
        "y_test_cat = test_masks_cat.reshape((y_test.shape[0], y_test.shape[1], y_test.shape[2], n_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxK1p9UhPt7b"
      },
      "outputs": [],
      "source": [
        "# define segmentation model parameters\n",
        "sm.set_framework('tf.keras')\n",
        "sm.framework()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9BuPrfVPyX8"
      },
      "outputs": [],
      "source": [
        "# loss functions and metrics\n",
        "dice_loss = sm.losses.DiceLoss(class_weights=np.array([0.25, 0.25, 0.25, 0.25])) \n",
        "focal_loss = sm.losses.CategoricalFocalLoss()\n",
        "total_loss = dice_loss + (1 * focal_loss)\n",
        "\n",
        "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1wxD71WP4qa"
      },
      "outputs": [],
      "source": [
        "# training parameters\n",
        "n_classes=4\n",
        "activation='softmax'\n",
        "\n",
        "LR = 0.0001\n",
        "optim = tf.keras.optimizers.Adam(LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoTjAgKnP7rn"
      },
      "outputs": [],
      "source": [
        "# initialize with pretrained weights from autoencoder\n",
        "input_shape = (256, 256, 3)\n",
        "random_wt_unet_model = build_unet(input_shape)\n",
        "\n",
        "random_wt_unet_model_weights = random_wt_unet_model.get_weights()[0][1]\n",
        "\n",
        "pre_trained_unet_model = build_unet(input_shape)\n",
        "pre_trained_unet_model.load_weights('unet_model_weights.h5')\n",
        "pre_trained_unet_model_weights = pre_trained_unet_model.get_weights()[0][1]\n",
        "\n",
        "#Load previously saved pretrained encoder weights just for comparison with the unet weights (Sanity check)\n",
        "pretrained_encoder_wts = np.load('pretrained_encoder-weights.npy')\n",
        "\n",
        "if pre_trained_unet_model_weights.all() == pretrained_encoder_wts.all():\n",
        "    print(\"Both weights are identical\")\n",
        "else: \n",
        "    print(\"Something wrong, weghts are different\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XW8O5S_UQDpY"
      },
      "outputs": [],
      "source": [
        "# compile the models\n",
        "random_wt_unet_model.compile('Adam', loss=sm.losses.categorical_focal_jaccard_loss, metrics=[sm.metrics.iou_score])\n",
        "pre_trained_unet_model.compile('Adam', loss=sm.losses.categorical_focal_jaccard_loss, metrics=[sm.metrics.iou_score])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train the models\n",
        "batch_size=16\n",
        "\n",
        "random_wt_unet_model_history = random_wt_unet_model.fit(X_train, y_train, \n",
        "                    verbose=1,\n",
        "                    batch_size = batch_size,\n",
        "                    validation_data=(X_do_not_use, y_do_not_use), \n",
        "                    shuffle=False,\n",
        "                    epochs=25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Mean IoU score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get the predictions for the test data\n",
        "y_pred=model.predict(X_test)\n",
        "y_pred_argmax=np.argmax(y_pred, axis=3)\n",
        "\n",
        "# check mean Intersection over Union score (IoU)\n",
        "n_classes = 4\n",
        "IOU_keras = MeanIoU(num_classes=n_classes)  \n",
        "IOU_keras.update_state(y_test[:,:,:,0], y_pred_argmax)\n",
        "print(\"Mean IoU =\", IOU_keras.result().numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### IoU metric per class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "values = np.array(IOU_keras.get_weights()).reshape(n_classes, n_classes)\n",
        "print(values)\n",
        "class1_IoU = values[0,0]/(values[0,0] + values[0,1] + values[0,2] + values[0,3] + values[1,0]+ values[2,0]+ values[3,0])\n",
        "class2_IoU = values[1,1]/(values[1,1] + values[1,0] + values[1,2] + values[1,3] + values[0,1]+ values[2,1]+ values[3,1])\n",
        "class3_IoU = values[2,2]/(values[2,2] + values[2,0] + values[2,1] + values[2,3] + values[0,2]+ values[1,2]+ values[3,2])\n",
        "class4_IoU = values[3,3]/(values[3,3] + values[3,0] + values[3,1] + values[3,2] + values[0,3]+ values[1,3]+ values[2,3])\n",
        "\n",
        "print(\"IoU for class1 is: \", class1_IoU)\n",
        "print(\"IoU for class2 is: \", class2_IoU)\n",
        "print(\"IoU for class3 is: \", class3_IoU)\n",
        "print(\"IoU for class4 is: \", class4_IoU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get the predictions for the test data\n",
        "y_pred=model.predict(X_test)\n",
        "y_pred_argmax=np.argmax(y_pred, axis=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check mean Intersection over Union score (IoU)\n",
        "n_classes = 4\n",
        "IOU_keras = MeanIoU(num_classes=n_classes)  \n",
        "IOU_keras.update_state(y_test[:,:,:,0], y_pred_argmax)\n",
        "print(\"Mean IoU =\", IOU_keras.result().numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plotting the predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plotting\n",
        "\n",
        "#getting and preping prediction on test image\n",
        "test_img_number = random.randint(0, len(X_test)) # take a random image patch\n",
        "test_img = X_test[test_img_number] \n",
        "ground_truth=y_test[test_img_number] # mask for the test image patch\n",
        "test_img_norm=test_img[:,:,0][:,:,None] # normalizing the test image patch\n",
        "test_img_input=np.expand_dims(test_img_norm, 0) # expanding the dimensions for prediction\n",
        "prediction = (model.predict(test_img_input))\n",
        "predicted_img=np.argmax(prediction, axis=3)[0,:,:] \n",
        "\n",
        "# plot the test image patch\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.subplot(231)\n",
        "plt.title('Testing Image')\n",
        "plt.imshow(test_img[:,:,0], cmap='gray')\n",
        "plt.subplot(232)\n",
        "plt.title('Testing Label')\n",
        "plt.imshow(ground_truth[:,:,0], cmap='jet')\n",
        "plt.subplot(233)\n",
        "plt.title('Prediction on test image')\n",
        "plt.imshow(predicted_img, cmap='jet')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
